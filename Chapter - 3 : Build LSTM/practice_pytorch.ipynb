{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Pytorch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function that helps us to describe various properties of tensors.\n",
    "def describe(x):\n",
    "    print(\"Type : {}\".format(x.type()))\n",
    "    print(\"Shape/size : {}\".format(x.shape))\n",
    "    print(\"Values : \\n{}\\n\".format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : torch.FloatTensor\n",
      "Shape/size : torch.Size([2, 3])\n",
      "Values : \n",
      "tensor([[-1.9619e-32,  3.0761e-41, -2.0823e-32],\n",
      "        [ 3.0761e-41,  1.1210e-43,  0.0000e+00]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating tensor with torch.Tensor\n",
    "import torch\n",
    "describe(torch.Tensor(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : torch.FloatTensor\n",
      "Shape/size : torch.Size([2, 3])\n",
      "Values : \n",
      "tensor([[4.6971e-01, 9.7573e-01, 5.1737e-05],\n",
      "        [6.6069e-01, 9.2494e-01, 1.8244e-01]])\n",
      "\n",
      "Type : torch.FloatTensor\n",
      "Shape/size : torch.Size([2, 3])\n",
      "Values : \n",
      "tensor([[ 1.5903, -0.7021,  1.0048],\n",
      "        [ 0.4791, -1.1222, -0.1503]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "describe(torch.rand(2,3)) # Uniform random\n",
    "describe(torch.randn(2,3)) # random normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : torch.FloatTensor\n",
      "Shape/size : torch.Size([2, 3])\n",
      "Values : \n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n",
      "Type : torch.FloatTensor\n",
      "Shape/size : torch.Size([2, 3])\n",
      "Values : \n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "\n",
      "Type : torch.FloatTensor\n",
      "Shape/size : torch.Size([2, 3])\n",
      "Values : \n",
      "tensor([[5., 5., 5.],\n",
      "        [5., 5., 5.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# creating tensor, filled with same scaler\n",
    "describe(torch.zeros(2,3))\n",
    "x = torch.ones(2,3)\n",
    "describe(x)\n",
    "x.fill_(5) # filling with 5 using fill_ function, inplace operations\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : torch.FloatTensor\n",
      "Shape/size : torch.Size([2, 3])\n",
      "Values : \n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# creating tensor using python list\n",
    "describe(torch.Tensor([[1,2,3],\n",
    "                        [4,5,6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : torch.DoubleTensor\n",
      "Shape/size : torch.Size([2, 3])\n",
      "Values : \n",
      "tensor([[0.0987, 0.5766, 0.6846],\n",
      "        [0.3974, 0.1256, 0.6732]], dtype=torch.float64)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# numpy array to tensor\n",
    "import numpy as np\n",
    "npy = np.random.rand(2,3)\n",
    "describe(torch.from_numpy(npy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : torch.FloatTensor\n",
      "Shape/size : torch.Size([2, 3])\n",
      "Values : \n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[1,2,3],\n",
    "                        [4,5,6]])\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : torch.LongTensor\n",
      "Shape/size : torch.Size([2, 3])\n",
      "Values : \n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = x.long()\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : torch.LongTensor\n",
      "Shape/size : torch.Size([2, 3])\n",
      "Values : \n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1,2,3],\n",
    "                    [4,5,6]],dtype = torch.int64)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : torch.FloatTensor\n",
      "Shape/size : torch.Size([2, 3])\n",
      "Values : \n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x =x.float()\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : torch.FloatTensor\n",
      "Shape/size : torch.Size([2, 3])\n",
      "Values : \n",
      "tensor([[ 0.1956, -1.2471, -0.6217],\n",
      "        [ 1.6830, -0.2809,  0.6461]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,3)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : torch.FloatTensor\n",
      "Shape/size : torch.Size([2, 3])\n",
      "Values : \n",
      "tensor([[ 0.3913, -2.4941, -1.2433],\n",
      "        [ 3.3660, -0.5618,  1.2923]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "describe(torch.add(x,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : torch.FloatTensor\n",
      "Shape/size : torch.Size([2, 3])\n",
      "Values : \n",
      "tensor([[ 0.3913, -2.4941, -1.2433],\n",
      "        [ 3.3660, -0.5618,  1.2923]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "describe(x+x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : torch.LongTensor\n",
      "Shape/size : torch.Size([6])\n",
      "Values : \n",
      "tensor([0, 1, 2, 3, 4, 5])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(6)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : torch.LongTensor\n",
      "Shape/size : torch.Size([2, 3])\n",
      "Values : \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = x.view(2,3)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : torch.LongTensor\n",
      "Shape/size : torch.Size([3])\n",
      "Values : \n",
      "tensor([3, 5, 7])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "describe(torch.sum(x,dim= 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : torch.LongTensor\n",
      "Shape/size : torch.Size([2])\n",
      "Values : \n",
      "tensor([ 3, 12])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "describe(torch.sum(x,dim= 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : torch.LongTensor\n",
      "Shape/size : torch.Size([3, 2])\n",
      "Values : \n",
      "tensor([[0, 3],\n",
      "        [1, 4],\n",
      "        [2, 5]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "describe(torch.transpose(x,0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing, Slicing and Joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : torch.LongTensor\n",
      "Shape/size : torch.Size([2, 3])\n",
      "Values : \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x  = torch.arange(6).view(2,3)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : torch.LongTensor\n",
      "Shape/size : torch.Size([1, 2])\n",
      "Values : \n",
      "tensor([[0, 1]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "describe(x[:1,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : torch.LongTensor\n",
      "Shape/size : torch.Size([2, 2])\n",
      "Values : \n",
      "tensor([[0, 2],\n",
      "        [3, 5]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indices = torch.LongTensor([0,2])\n",
    "describe(torch.index_select(x,dim = 1,index = indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : torch.LongTensor\n",
      "Shape/size : torch.Size([2, 3])\n",
      "Values : \n",
      "tensor([[0, 1, 2],\n",
      "        [0, 1, 2]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indices = torch.LongTensor([0,0])\n",
    "describe(torch.index_select(x,dim = 0,index = indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : torch.LongTensor\n",
      "Shape/size : torch.Size([2])\n",
      "Values : \n",
      "tensor([0, 4])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "row_indices = torch.arange(2).long()\n",
    "col_indices = torch.LongTensor([0,1])\n",
    "describe(x[row_indices,col_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1]), tensor([0, 1]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_indices,col_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : torch.LongTensor\n",
      "Shape/size : torch.Size([6])\n",
      "Values : \n",
      "tensor([0, 1, 2, 3, 4, 5])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dimention based tensor operations\n",
    "x = torch.arange(6)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : torch.LongTensor\n",
      "Shape/size : torch.Size([2, 3])\n",
      "Values : \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = x.view(2,3)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : torch.LongTensor\n",
      "Shape/size : torch.Size([3])\n",
      "Values : \n",
      "tensor([3, 5, 7])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "describe(torch.sum(x,dim = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : torch.LongTensor\n",
      "Shape/size : torch.Size([2])\n",
      "Values : \n",
      "tensor([ 3, 12])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "describe(torch.sum(x,dim = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : torch.LongTensor\n",
      "Shape/size : torch.Size([3, 2])\n",
      "Values : \n",
      "tensor([[0, 3],\n",
      "        [1, 4],\n",
      "        [2, 5]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "describe(torch.transpose(x,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : torch.LongTensor\n",
      "Shape/size : torch.Size([2, 3])\n",
      "Values : \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(6).view(2,3)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : torch.LongTensor\n",
      "Shape/size : torch.Size([4, 3])\n",
      "Values : \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "describe(torch.cat([x,x],dim = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : torch.LongTensor\n",
      "Shape/size : torch.Size([2, 6])\n",
      "Values : \n",
      "tensor([[0, 1, 2, 0, 1, 2],\n",
      "        [3, 4, 5, 3, 4, 5]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "describe(torch.cat([x,x],dim = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : torch.LongTensor\n",
      "Shape/size : torch.Size([2, 2, 3])\n",
      "Values : \n",
      "tensor([[[0, 1, 2],\n",
      "         [3, 4, 5]],\n",
      "\n",
      "        [[0, 1, 2],\n",
      "         [3, 4, 5]]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "describe(torch.stack([x,x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : torch.LongTensor\n",
      "Shape/size : torch.Size([2, 3])\n",
      "Values : \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Linear algebra on tensors\n",
    "x1 = torch.arange(6).view(2,3)\n",
    "describe(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : torch.FloatTensor\n",
      "Shape/size : torch.Size([3, 2])\n",
      "Values : \n",
      "tensor([[1., 2.],\n",
      "        [1., 2.],\n",
      "        [1., 2.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x2 = torch.ones(3,2)\n",
    "x2[:,1] += 1\n",
    "describe(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : torch.FloatTensor\n",
      "Shape/size : torch.Size([2, 2])\n",
      "Values : \n",
      "tensor([[ 3.,  6.],\n",
      "        [12., 24.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "describe(torch.mm(x1.float(),x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : torch.FloatTensor\n",
      "Shape/size : torch.Size([2, 2])\n",
      "Values : \n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Tensors and computational graphs\n",
    "x = torch.ones(2,2,requires_grad=True)\n",
    "describe(x)\n",
    "print(x.grad is None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : torch.FloatTensor\n",
      "Shape/size : torch.Size([2, 2])\n",
      "Values : \n",
      "tensor([[21., 21.],\n",
      "        [21., 21.]], grad_fn=<AddBackward0>)\n",
      "\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "y = (x+2) * (x+5) + 3\n",
    "describe(y)\n",
    "print(x.grad is None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : torch.FloatTensor\n",
      "Shape/size : torch.Size([])\n",
      "Values : \n",
      "21.0\n",
      "\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "z = y.mean()\n",
    "describe(z)\n",
    "z.backward()\n",
    "print(x.grad is None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# cuda tebsors\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : torch.FloatTensor\n",
      "Shape/size : torch.Size([3, 3])\n",
      "Values : \n",
      "tensor([[0.7995, 0.2596, 0.1187],\n",
      "        [0.1659, 0.1538, 0.2920],\n",
      "        [0.7364, 0.2568, 0.8920]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3,3).to(device)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.rand(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8785, 0.9204, 0.7497],\n",
       "        [1.0933, 0.7871, 0.6031],\n",
       "        [1.2339, 0.2969, 1.0061]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_device = torch.device(\"cpu\")\n",
    "y = y.to(cpu_device)\n",
    "x = x.to(cpu_device)\n",
    "x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.randn(2,3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-6.6490e-01,  8.5567e-01,  8.8609e-01],\n",
       "         [-5.8702e-01, -8.9637e-01, -6.1950e-01],\n",
       "         [-7.6487e-01, -2.5398e-01,  2.5273e-01],\n",
       "         [ 7.0716e-01, -1.5067e-01,  7.5551e-02],\n",
       "         [ 5.1466e-01,  7.4693e-02, -2.1479e+00]],\n",
       "\n",
       "        [[-1.7718e+00, -1.4730e+00,  2.4675e-01],\n",
       "         [ 6.8794e-01,  4.0592e-04,  4.0941e-01],\n",
       "         [-3.2978e-01,  2.3241e+00,  2.1310e-01],\n",
       "         [ 5.5533e-01,  1.1551e+00, -1.3274e+00],\n",
       "         [ 8.8148e-01, -2.8631e-01, -6.7561e-01]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.transpose(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "k,q,v = None,None,8\n",
    "\n",
    "if (k and q and v) is None:\n",
    "    raise ValueError(\"keys or values or queries is None\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1,5,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 10])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,0::2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 10])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,1::2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import torch\n",
    "import plotly.express as px\n",
    "pd.options.plotting.backend = \"plotly\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_enc(pos,i,d_model,sine_type = \"sin\"):\n",
    "    denom = pos/torch.pow(torch.tensor(10000),(2*i)/d_model)\n",
    "    if sine_type == \"sin\":\n",
    "        out = torch.sin(denom)\n",
    "        return out\n",
    "    if sine_type == \"cos\":\n",
    "        out = torch.cos(denom)\n",
    "        return out\n",
    "    else:\n",
    "        raise NotImplementedError(f\"given sine_type {sine_type} is not implemented\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sin_cos_plot(d_model,num_words=2):\n",
    "    out = {}\n",
    "    for pos in range(1,num_words+1):\n",
    "        embeddings =torch.arange(0,d_model).float()\n",
    "        embeddings[0::2] = pos_enc(pos,embeddings[0::2],d_model=d_model,sine_type=\"sin\")\n",
    "        embeddings[1::2] = pos_enc(pos,embeddings[1::2],d_model=d_model,sine_type=\"cos\")\n",
    "        out[pos] = embeddings.data\n",
    "\n",
    "    data = pd.DataFrame(out)\n",
    "    fig1 = data.plot()\n",
    "    fig1.show()\n",
    "sin_cos_plot(2,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([inf, inf, inf, inf, inf])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fab0c0472e0>]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "exp = torch.exp(torch.arange(256))\n",
    "print(exp[-5:])\n",
    "plt.plot(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-inf, -inf, -inf, -inf, -inf])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fab07feb5b0>]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "exp = torch.exp(torch.arange(256)) * -torch.log(torch.tensor(10000))/512\n",
    "print(exp[-5:])\n",
    "plt.plot(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div_term = torch.exp(torch.arange(0, 512, 2) * (-math.log(10000.0) / 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(torch.tensor(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 1.5849e-01, 2.5119e-02, 3.9811e-03, 6.3096e-04])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_model = 10\n",
    "torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.9811e-01, 6.3096e-02, 1.0000e-02, 1.5849e-03, 2.5119e-04])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(torch.arange(1, d_model, 2) * (-math.log(10000.0) / d_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "class NewModule(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(NewModule, self).__init__()\n",
    "        # Pre_matrix: NXP, of size 700MB, requires_grad=False\n",
    "        self.pre_matrix = torch.tensor([2,3,4,5])\n",
    "        # self.pre_matrix.requires_grad=False\n",
    "        # self.register_buffer('pre_matrix', pre_matrix)  ### this means the stat_dic is larger than 700MB\n",
    "\n",
    "    def forward(self, input):\n",
    "        # input: MXN, on multiple gpus\n",
    "        # output: MXP, on multiple gpus\n",
    "        out = input @ self.pre_matrix\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Run(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.nothing = NewModule()\n",
    "\n",
    "    def forward(self,x):\n",
    "        \n",
    "        y = self.nothing(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "myclass = Run()\n",
    "ins = torch.tensor([2,3,4,5])\n",
    "y = myclass(ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in myclass.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Run(\n",
       "  (nothing): NewModule()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    batch_sz = 2\n",
    "    d_model_sz = 512\n",
    "    seq_len = 5\n",
    "    hidden_sz = 2048\n",
    "    embedding_sz = 512\n",
    "    n_heads = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/ravikumar/Desktop/NLP/Learning-NLP-with-PyTorch/Chapter - 3 : Build LSTM/practice_pytorch.ipynb Cell 71\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ravikumar/Desktop/NLP/Learning-NLP-with-PyTorch/Chapter%20-%203%20%3A%20Build%20LSTM/practice_pytorch.ipynb#Y130sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m {k:v \u001b[39mfor\u001b[39;00m k,v \u001b[39min\u001b[39;00m Config\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m__\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m k}\n",
      "\u001b[1;32m/home/ravikumar/Desktop/NLP/Learning-NLP-with-PyTorch/Chapter - 3 : Build LSTM/practice_pytorch.ipynb Cell 71\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ravikumar/Desktop/NLP/Learning-NLP-with-PyTorch/Chapter%20-%203%20%3A%20Build%20LSTM/practice_pytorch.ipynb#Y130sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m {k:v \u001b[39mfor\u001b[39;00m k,v \u001b[39min\u001b[39;00m Config\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m__\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m k}\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "{k:v for k,v in Config.__dict__ if \"__\" not in k}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable int object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ravikumar/Desktop/NLP/Learning-NLP-with-PyTorch/Chapter - 3 : Build LSTM/practice_pytorch.ipynb Cell 72\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ravikumar/Desktop/NLP/Learning-NLP-with-PyTorch/Chapter%20-%203%20%3A%20Build%20LSTM/practice_pytorch.ipynb#Y131sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m a,b,c \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable int object"
     ]
    }
   ],
   "source": [
    "a,b,c = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen = \"how are you doing\"\n",
    "inputs = [\"SOS\",\"how\",\"are\",\"you\"]\n",
    "shifted_right = ['how',\"are\",\"you\",\"doing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index = {\"SOS\":0,\"how\":1,\"are\":2,\"you\":3,\"doing\":4}\n",
    "index2word = {i:w for w,i in word2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = nn.Embedding(5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "ins = torch.tensor([0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_input = embs(ins).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.4359, -0.3748, -1.0442],\n",
       "         [-0.1581,  0.2255,  2.0028],\n",
       "         [-0.0647,  0.0616,  0.0286],\n",
       "         [ 1.0268, -0.3816,  1.7170]]], grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_input = torch.tensor([[[ 1.4359, -0.3748, -1.0442],\n",
    "         [-0.1581,  0.2255,  2.0028],\n",
    "         [-0.0647,  0.0616,  0.0286],\n",
    "         [ 1.0268, -0.3816,  1.7170]]],requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1581,  0.2255,  2.0028],\n",
       "         [-0.0647,  0.0616,  0.0286],\n",
       "         [ 1.0268, -0.3816,  1.7170],\n",
       "         [-0.5707, -0.0059,  2.7354]]], grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = torch.tensor([1,2,3,4])\n",
    "my_output = embs(out).unsqueeze(0)\n",
    "my_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "rightshift_input = torch.tensor([[[-0.1581,  0.2255,  2.0028],\n",
    "         [-0.0647,  0.0616,  0.0286],\n",
    "         [ 1.0268, -0.3816,  1.7170],\n",
    "         [-0.5707, -0.0059,  2.7354]]],requires_grad= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x =  torch.arange(0, 4*4).view(4,4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  5, 10, 15])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('ii->i',x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# For the shake of simlicity, let's take a 3 inputs each  with dimention of 4.\n",
    "\n",
    "x = torch.randn(3,4,dtype = torch.float32)\n",
    "\n",
    "def attention(k,q,v):\n",
    "    keys = torch.matmul(q , k.T)\n",
    "    scores = softmax(keys, dim=-1)\n",
    "    output = torch.matmul(scores,v) # (3,3) * (3,4) > (3,4)\n",
    "    return output,scores\n",
    "\n",
    "output,scores = attention(x,x,x)\n",
    "print(\"input \\n\",x)\n",
    "print(\"output \\n\",output)\n",
    "print(\"scores \\n\",scores)\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Jun  1 2022, 11:38:51) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ecc1e0c57004a42925f1a7d3528192b163c048a803ed4402c89cd3dd7f075304"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
